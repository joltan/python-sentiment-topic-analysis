{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1578f070-79ae-42f6-8dc2-458db4ab66ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "791f8c54-373b-482a-aaa8-eb56c26f50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_reviews_from_page(url):\n",
    "    try:\n",
    "        req = requests.get(url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "        req.raise_for_status()  # Raise an error for bad status codes\n",
    "        time.sleep(2)  # Add a delay to avoid overwhelming the server\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        reviews_raw = soup.find(\"script\", id=\"__NEXT_DATA__\").string\n",
    "        reviews_raw = json.loads(reviews_raw)\n",
    "        return reviews_raw[\"props\"][\"pageProps\"][\"reviews\"]\n",
    "    except (requests.RequestException, json.JSONDecodeError, AttributeError) as e:\n",
    "        return []\n",
    "\n",
    "def scrape_trustpilot_reviews(base_url: str, page_limit: int = None):\n",
    "    reviews_data = []\n",
    "\n",
    "    page_number = 1\n",
    "    while True:\n",
    "        if page_limit is not None and page_number > page_limit:\n",
    "            break\n",
    "\n",
    "        print(f\"Scraping page {page_number}\")\n",
    "        url = f\"{base_url}?page={page_number}\"\n",
    "        reviews = get_reviews_from_page(url)\n",
    "\n",
    "        if not reviews:\n",
    "            break\n",
    "\n",
    "        for review in reviews:\n",
    "            data = {\n",
    "                'Date': pd.to_datetime(review[\"dates\"][\"publishedDate\"]).strftime(\"%Y-%m-%d\"),\n",
    "                'Author': review[\"consumer\"][\"displayName\"],\n",
    "                'Body': review[\"text\"],\n",
    "                'Heading': review[\"title\"],\n",
    "                'Rating': review[\"rating\"],\n",
    "                'Location': review[\"consumer\"][\"countryCode\"]\n",
    "            }\n",
    "            reviews_data.append(data)\n",
    "        \n",
    "        page_number += 1\n",
    "\n",
    "    # Remove duplicates based on the 'Body' field\n",
    "    reviews_data = [dict(t) for t in {tuple(d.items()) for d in reviews_data}]\n",
    "    \n",
    "    return reviews_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca490b25-eda6-4fe0-8abb-537f990a66c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n",
      "Scraping page 3\n",
      "Scraping page 4\n",
      "Scraping page 5\n",
      "Scraping page 6\n",
      "Scraping page 7\n",
      "Scraping page 8\n",
      "Scraping page 9\n",
      "Scraping page 10\n",
      "Scraping page 11\n",
      "Scraping page 12\n",
      "Scraping page 13\n",
      "Scraping page 14\n",
      "Scraping page 15\n",
      "Scraping page 16\n",
      "Scraping page 17\n",
      "Scraping page 18\n",
      "Scraping page 19\n",
      "Scraping page 20\n",
      "Scraping page 21\n",
      "Scraping page 22\n",
      "Scraping page 23\n",
      "Scraping page 24\n",
      "Scraping page 25\n",
      "Scraping page 26\n",
      "Scraping page 27\n",
      "Scraping page 28\n",
      "Scraping page 29\n",
      "Scraping page 30\n",
      "Scraping page 31\n",
      "Scraping page 32\n",
      "Scraping page 33\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Scrape the reviews from the specified URL\n",
    "\n",
    "base_url_discord = \"https://www.trustpilot.com/review/discordapp.com\"\n",
    "page_limit_discord = 33  # Set the number of pages you want to scrape\n",
    "reviews = scrape_trustpilot_reviews(base_url_discord, page_limit=page_limit_discord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0dabf80-2621-481e-bdd3-8f48743c6a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "Scraping page 2\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Scrape the reviews from the specified URL\n",
    "\n",
    "base_url_signal = \"https://www.trustpilot.com/review/signal.org\"\n",
    "page_limit_signal = 2  # Set the number of pages you want to scrape\n",
    "reviews_signal = scrape_trustpilot_reviews(base_url_signal, page_limit=page_limit_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b6567-79bc-46db-9f19-151113f7ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Scrape the reviews from the specified URL\n",
    "\n",
    "base_url_whatsapp = \"https://www.trustpilot.com/review/whatsapp\"\n",
    "page_limit_whatsapp = 22  # Set the number of pages you want to scrape\n",
    "reviews_whatsapp = scrape_trustpilot_reviews(base_url_whatsapp, page_limit=page_limit_whatsapp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "621b6a2f-bedc-46b4-83b4-8bd0d6cca56c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reviews_discord' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 4: Create a DataFrame from the reviews data and save to CSV and JSON files\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_reviews_discord \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mreviews_discord\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Save to CSV\u001b[39;00m\n\u001b[1;32m      6\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreviews_discord.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reviews_discord' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Create a DataFrame from the reviews data and save to CSV and JSON files\n",
    "\n",
    "df_reviews_discord = pd.DataFrame(reviews_discord)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'reviews_discord.csv'\n",
    "df_reviews.to_csv(csv_path, index=False)\n",
    "print(f\"DataFrame written to {csv_path}\")\n",
    "\n",
    "# Save to JSON\n",
    "json_path = 'reviews_discord.json'\n",
    "df_reviews.to_json(json_path, orient='records', lines=True)\n",
    "print(f\"DataFrame written to {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88862bc-c59a-4067-a64c-901ffed9d892",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Create a DataFrame from the reviews data and save to CSV and JSON files\n",
    "\n",
    "df_reviews = pd.DataFrame(reviews_whatsapp)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'reviews_discord.csv'\n",
    "df_reviews.to_csv(csv_path, index=False)\n",
    "print(f\"DataFrame written to {csv_path}\")\n",
    "\n",
    "# Save to JSON\n",
    "json_path = 'reviews_discord.json'\n",
    "df_reviews.to_json(json_path, orient='records', lines=True)\n",
    "print(f\"DataFrame written to {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3370b55d-7d60-4815-b618-d713dfe06650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame written to reviews_discord.csv\n",
      "DataFrame written to reviews_discord.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Create a DataFrame from the reviews data and save to CSV and JSON files\n",
    "\n",
    "df_reviews = pd.DataFrame(reviews_signal)\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'reviews_discord.csv'\n",
    "df_reviews.to_csv(csv_path, index=False)\n",
    "print(f\"DataFrame written to {csv_path}\")\n",
    "\n",
    "# Save to JSON\n",
    "json_path = 'reviews_discord.json'\n",
    "df_reviews.to_json(json_path, orient='records', lines=True)\n",
    "print(f\"DataFrame written to {json_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8623072-e885-47e9-840c-35e8b9b90548",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
